{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogFormatterExponent\n",
    "from DTA.enrichment_plotters import polar_plot, get_file_list, get_helices, read_rep\n",
    "from DTA.polarDensity_helper import Coord_Get, get_header_info\n",
    "from DTA.site_distributions import outline_site, make_symmetric_sites, combine_sites, plot_density, Site\n",
    "from plotting import make_custom_colormap\n",
    "my_cmap = make_custom_colormap()\n",
    "plt.rcParams['axes.grid'] = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify one or more sites from enrichment plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipids = [\"POPG\", \"POPE\"] # or the lipids of choice\n",
    "leaflets = ['low', 'upp'] # analyze both leaflets (default)\n",
    "root = Path(\"/path/to/files\") \n",
    "replicas = [\"rep1\", \"rep2\", \"rep3\"] # replicas as identified in the \"root\" directory\n",
    "helix_definitions = root.joinpath(replicas[2]) #where are the coordinates for the transmembrane helices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate read and parse the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments = None\n",
    "counts = None\n",
    "helices_upr, helices_lwr = get_helices(helix_definitions)\n",
    "for rep in replicas:\n",
    "    reppath = root.joinpath(rep)\n",
    "    file_list = get_file_list(reppath, lipids)\n",
    "    rad, dr, dth, theta, radius, frames, Ntheta = Coord_Get(file_list[0])\n",
    "    cts, rich = read_rep(file_list, lipids, leaflets, enrich=True)\n",
    "    if counts is None:\n",
    "        counts = cts\n",
    "        enrichments = rich\n",
    "    else:\n",
    "        counts = counts+cts\n",
    "        enrichments = enrichments+rich\n",
    "    \n",
    "\n",
    "counts = counts/len(replicas)\n",
    "enrichments = enrichments/len(replicas)\n",
    "thetas = np.unique(theta.flatten())\n",
    "\n",
    "generic_settings ={'Ntheta':Ntheta,\n",
    "                   'dr':dr, \n",
    "                   'dth':dth,\n",
    "                   'exrho':1,\n",
    "                   'frames':frames,\n",
    "                   }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some putative sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site1def = {'theta_start':5, \n",
    "            'width':3, \n",
    "            'inner_r':24, \n",
    "            'outer_r':30, \n",
    "            'sitename':\"Site 1 \",\n",
    "            }\n",
    "\n",
    "site2def = {'theta_start':9,\n",
    "            'width':4,\n",
    "            'inner_r':22,\n",
    "            'outer_r':32,\n",
    "            'sitename':\"Site 2 \",\n",
    "            }\n",
    "\n",
    "dummy_sites_1 = make_symmetric_sites([], **site1def, **generic_settings)\n",
    "dummy_sites_2 = make_symmetric_sites([], **site2def, **generic_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot enrichments (you may need to go back and update your site definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pore density:\n",
    "enrichments.at['POPE', 'low'][0:3,:]=0\n",
    "\n",
    "fig, axes = polar_plot(enrichments, \n",
    "                       theta, \n",
    "                       radius, \n",
    "                       lipids, \n",
    "                       helices_lwr, \n",
    "                       helices_upr, \n",
    "                       colorbychain=False, \n",
    "                       vmin=0.75, \n",
    "                       vmax=1.5, \n",
    "                       vmid=1,\n",
    "                       figheight=8,\n",
    "                       figwidth=8,\n",
    "                       cmap=my_cmap)\n",
    "\n",
    "#this is where you decide which leaflet each site refers to 0==outer leaflet, 1==inner leaflet\n",
    "for site in dummy_sites_1:\n",
    "    axes[0] = outline_site(axes[0], site)\n",
    "\n",
    "for site in dummy_sites_2:\n",
    "     axes[1] = outline_site(axes[1], site)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(root.joinpath(\"ELIC_enrichments.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Accessible Area\n",
    "This process should be done for each site.\n",
    "1. Read in the data (update the user parameters according to your paths and leaflet of interest). If you have replicas or symmetric sites, you can load all of them and try to minimize the RMSE of your estimate.\n",
    "2. Get the total area of the site. This is your initial guess.\n",
    "3. Get/read the bulk bead distribution\n",
    "4. Calculate the accessible area and compare to your guess\n",
    "5. If the accessible area remains very similar to your guess, you're done. Otherwise, try a guess that's closer to the estimated accessible area and go back to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User parameters\n",
    "lipid = \"DPPC\"\n",
    "leaf = \"upp\"\n",
    "the_site_def = site1def\n",
    "data_root = Path(\"/Users/ezry/Projects/ELIC_DPPC/elicPE17_DPPC/\")\n",
    "fpath = data_root.joinpath(f\"{lipid}.dat.{leaf}.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mol,avg_A,beads,exrho,avg_chain = get_header_info(fpath)\n",
    "the_data = np.loadtxt(fpath, skiprows=1)\n",
    "rad, dr, dth, theta, radius, frames, Ntheta = Coord_Get(fpath)\n",
    "\n",
    "# Update exrho and frames based on the above since it will differ for DPPC. All other parameters are constant across systems.\n",
    "generic_settings['exrho'] = exrho\n",
    "generic_settings['frames'] = frames\n",
    "\n",
    "the_sites = make_symmetric_sites(the_data, **the_site_def, **generic_settings)\n",
    "symmetric_site = combine_sites(the_sites, exrho, f\"{the_site_def['sitename'][:-1]}, Symmetric\", symmetric=True)\n",
    "symmetric_site.Npeak = symmetric_site.peak #special case\n",
    "sites = { 'the_site_symmetric':symmetric_site,\n",
    "         }\n",
    "for site in the_sites:\n",
    "    sites[site.title] = site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: get the total area of the site in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Site Name':<20}:{'Atotal':>8}|{'peak'}\")\n",
    "for name, site in sites.items():\n",
    "    print(f\"{site.title:<20}:{np.round(site.area,1):>8}|{np.round(site.peak,0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: get the bulk density \n",
    "In VMD:\n",
    "1. load the trajectory of the empty membrane\n",
    "2. modify do_get_counts.tcl to have the total area of the site\n",
    "3. source do_get_counts.tcl\n",
    "\n",
    "OR \n",
    "\n",
    "using the get_counts.ipynb notebook (requires MDAnalysis):\n",
    "1. Optional: set make_movies to True. This will export mp4s of the bead counts as a top-down heatmap; may be useful for debugging.\n",
    "2. Update the path to the trajectory and load it\n",
    "3. Assign leaflets (either using a resid cutoff or a more robust method)\n",
    "4. update ``areas`` to be a list of one or more areas of interest\n",
    "\n",
    "Either method will output data files of the site bead counts over time.\n",
    "\n",
    "Provide the path to the outputs here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 50\n",
    "bulk_counts_path = Path(f\"../accessible_area/sample_counts_for_bulk_DPPC/counts_{area}.dat\")\n",
    "bulk_counts = np.loadtxt(bulk_counts_path)\n",
    "\n",
    "frequencies = np.bincount(bulk_counts.astype(int).flatten())\n",
    "probabilities = frequencies/np.sum(frequencies)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(probabilities)), probabilities)\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xlabel(f\"Number of beads in an area about {area} \"+r\"$\\AA^2$\")\n",
    "bulk_mode = np.argmax(probabilities)\n",
    "ax.vlines([bulk_mode], 0, np.max(probabilities), color = 'black', linestyles='dashed', label = f\"mode={bulk_mode}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the site densities and compare with the bulk mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = len(sites)\n",
    "fig, axes = plt.subplots(rows,cols, figsize=(10*cols,7*rows))\n",
    "\n",
    "for site, ax in zip(sites.values(), axes.flatten()):\n",
    "    ax = plot_density(site, ax)\n",
    "    ax.vlines([bulk_mode], 0, np.max(probabilities), color = 'black', linestyles='dashed')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(data_root.joinpath(\"Raw_distributions.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The accessible area is...\n",
    "ASSUMING $\\left(A_\\mathrm{acc} \\approx A_\\mathrm{bulk}\\right) \\forall A_\\mathrm{site}$\n",
    "\n",
    "$A_\\mathrm{acc} = A_\\mathrm{bulk} \\frac{M_\\mathrm{site}}{M_\\mathrm{bulk}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Site Name':<20}:{'Accessible Area':>5}\")\n",
    "areas = np.array([])\n",
    "warnings = []\n",
    "for name, site in sites.items():\n",
    "    counts = site.counts.astype(int)\n",
    "    bincounts = np.bincount(counts.flatten())\n",
    "    the_mode = np.argmax(bincounts)\n",
    "    if the_mode == 0:\n",
    "        warnings.append(f\"Warning: found an experimental mode of 0 for '{site.title},' using second highest peak\")\n",
    "        the_mode = np.argmax(bincounts[1:])+1\n",
    "    A_acc = area * the_mode / bulk_mode\n",
    "    areas = np.append(areas, A_acc)\n",
    "    print(f\"{site.title:<20}:{np.round(A_acc,1):>5}\")\n",
    "\n",
    "for warn in warnings:\n",
    "    print(warn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average site area is: {np.round(np.mean(areas[1:]),1)} square angstroms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {np.round(np.sqrt(np.mean(np.square(areas[1:]-area))),1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
